{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入pos和unlabeled数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_all = \"/media/jw/5dccc50e-7c13-4186-bf6b-d894f02410be/wbb/result/pu_learning/\"\n",
    "train_pos_features_f = path_all + \"tpp_features/12*/part-*\"\n",
    "train_unlabled_features_f = path_all + \"train_unlabled_features/part-*\"\n",
    "test_pos_features_f = path_all + \"test_pp_features/1231/part-*\"\n",
    "test_unlabled_features_f = path_all + \"test_unlabled_features/part-*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pos_features = sc.textFile(train_pos_features_f).coalesce(50).map(lambda x: (eval(x)[0], [i for y in eval(x)[1] for i in y ]))\n",
    "train_unlabled_features = sc.textFile(train_unlabled_features_f).coalesce(100).map(lambda x: (eval(x)[0], [i for y in eval(x)[1] for i in y ]))\n",
    "test_pos_features = sc.textFile(test_pos_features_f).coalesce(50).map(lambda x: (eval(x)[0], [i for y in eval(x)[1] for i in y ]))\n",
    "test_unlabled_features = sc.textFile(test_unlabled_features_f).coalesce(100).map(lambda x: (eval(x)[0], [i for y in eval(x)[1] for i in y ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235586\n",
      "8268837\n",
      "77653\n",
      "8342347\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(train_pos_features.count())  # 235586\n",
    "print(train_unlabled_features.count())  # 8268837\n",
    "print(test_pos_features.count())  # 77653\n",
    "print(test_unlabled_features.count())  # 8342347\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从unlabled中抽取alfa进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alfa = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 从unlabled中抽取alfa作为negative\n",
    "### train_neg_features = random.sample(train_unlabled_features.collect(), int(alfa * 8268837))  # 太慢了\n",
    "# train_neg_features = train_unlabled_features.takeSample(False, int(alfa * 8268837))\n",
    "# sc.parallelize(train_neg_features).coalesce(10).saveAsTextFile(path_all + \"train_neg_features_01\")\n",
    "train_neg_features = sc.textFile(path_all + \"train_neg_features_01\").map(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_neg_features = random.sample(test_unlabled_features.collect(), int(alfa * 8342347))\n",
    "# test_neg_features = test_unlabled_features.takeSample(False, int(alfa * 8342347))\n",
    "# sc.parallelize(test_neg_features).coalesce(10).saveAsTextFile(path_all + \"test_neg_features_01\")\n",
    "test_neg_features = sc.textFile(path_all + \"test_neg_features_01\").map(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从pos中取一部分作为spy加入unlabeled中构建PU数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blta = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pnsplit = int(train_pos_features.count()*blta)   # pnsplit以前的部分作为pu_pos, 以后的部分作为pu_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pu_pos_features = train_pos_features.collect()[:pnsplit]\n",
    "pu_neg_features = train_pos_features.collect()[pnsplit:] + train_neg_features.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188468 874001\n"
     ]
    }
   ],
   "source": [
    "print(len(pu_pos_features), len(pu_neg_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从PU数据集抽取gamma部分作为PU训练，其余作为PU测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gamma=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pu_train_pos = sc.parallelize(pu_pos_features, 50).takeSample(False, int(len(pu_pos_features) * gamma))  # list\n",
    "# random.sample(pu_pos_features, int(len(pu_pos_features) * gamma))\n",
    "# pu_test_pos = [item for item in pu_pos_features if item not in pu_train_pos]\n",
    "pu_test_pos = sc.parallelize(pu_pos_features).subtractByKey(sc.parallelize(pu_train_pos)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113080 75388\n"
     ]
    }
   ],
   "source": [
    "print(len(pu_train_pos), len(pu_test_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pu_train_neg = random.sample(pu_neg_features, int(len(pu_neg_features) * gamma))\n",
    "# pu_test_neg = [item for item in pu_neg_features if item not in pu_train_neg]\n",
    "pu_train_neg = sc.parallelize(pu_neg_features, 50).takeSample(False, int(len(pu_neg_features) * gamma))  # list\n",
    "pu_test_neg = sc.parallelize(pu_neg_features).subtractByKey(sc.parallelize(pu_train_neg)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524400 349601\n"
     ]
    }
   ],
   "source": [
    "print(len(pu_train_neg), len(pu_test_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PU训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pu_train_data = sc.parallelize(pu_train_pos).map(lambda x: Row(label=1.0, features=Vectors.dense(x[1])))\\\n",
    "            .union(sc.parallelize(pu_train_neg).map(lambda x: Row(label=0.0, features=Vectors.dense(x[1])))).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pu_test_data = sc.parallelize(pu_test_pos).map(lambda x: Row(label=1.0, features=Vectors.dense(x[1])))\\\n",
    "            .union(sc.parallelize(pu_test_neg).map(lambda x: Row(label=0.0, features=Vectors.dense(x[1])))).toDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "publr = LogisticRegression(maxIter=15, regParam=0.024).fit(pu_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pu_test_data_preRes = publr.transform(pu_test_data.select(\"features\")).join(pu_test_data, 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aaa = pu_test_data_preRes.filter(pu_test_data_preRes.prediction == 0).filter(pu_test_data_preRes.label == 0)\\\n",
    ".select('features', 'probability').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_to_0_prob = []\n",
    "for i in aaa:\n",
    "    if i.features[-1] != 0 and i.features[-2] != 0:\n",
    "        predict_to_0_prob.append(i.probability[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5881 0.955686527802 0.500010760552 0.683705352903\n"
     ]
    }
   ],
   "source": [
    "print(len(predict_to_0_prob), max(predict_to_0_prob), min(predict_to_0_prob), sum(predict_to_0_prob)/len(predict_to_0_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bbb = pu_test_data_preRes.filter(pu_test_data_preRes.label == 0).select('features', 'probability').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RN = []\n",
    "for i in bbb:\n",
    "    if i.probability[0] > max(predict_to_0_prob):\n",
    "        RN.append(i.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90595 [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,7.0,5.0,3.0,8.0,3.0,3.0,5.0,7.0,10.0,8.0,0.0,11.0,6.0,7.0,3.0,0.0,0.0,0.0,0.0,0.0,10.0,9.0,7.0,12.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,30.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8.0,0.0,0.0,0.0,0.0,22.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,23.0,0.0,0.0,0.0,0.0,0.0,0.0,7.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n"
     ]
    }
   ],
   "source": [
    "print(len(RN), RN[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_pos_features.map(lambda x: Row(label=1.0, features=Vectors.dense(x[1])))\\\n",
    "            .union(sc.parallelize(RN).map(lambda x: Row(label=0.0, features=x))).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|\n",
      "|[1.0,0.0,0.0,0.0,...|  1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = test_pos_features.map(lambda x: Row(label=1.0, features=Vectors.dense(x[1])))\\\n",
    "            .union(test_neg_features.map(lambda x: Row(label=0.0, features=Vectors.dense(x[1])))).toDF()\n",
    "test_data.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对第4天进行预测"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.不用PU的情况\n",
    "2.用不同算法的情况\n",
    "3.改变alpha，belta的情况\n",
    "\n",
    "f1-score, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR =  LogisticRegression(maxIter=15, regParam=0.024).fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_4th_day = LR.transform(test_data.select('features')).join(test_data, 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+-----+\n",
      "|            features|       rawPrediction|         probability|prediction|label|\n",
      "+--------------------+--------------------+--------------------+----------+-----+\n",
      "|[0.0,0.0,0.0,0.0,...|[-1.0493904964668...|[0.25934215940090...|       1.0|  1.0|\n",
      "|[0.0,0.0,0.0,0.0,...|[0.30648903945096...|[0.57602804497085...|       0.0|  0.0|\n",
      "|[0.0,0.0,0.0,0.0,...|[0.35946059400152...|[0.58890985280857...|       0.0|  0.0|\n",
      "+--------------------+--------------------+--------------------+----------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_4th_day.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = (predict_4th_day.filter(predict_4th_day.prediction == predict_4th_day.label).count())/(predict_4th_day.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9577931304217632"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### without PU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_noPU = train_pos_features.map(lambda x: Row(label=1.0, features=Vectors.dense(x[1])))\\\n",
    "            .union(sc.parallelize(train_neg_features.takeSample(False, int(250000)))\\\n",
    "                   .map(lambda x: Row(label=0.0, features=Vectors.dense(x[1])))).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_noPU.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_noPU.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR_noPU = LogisticRegression(maxIter=15, regParam=0.024).fit(train_data_noPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_4th_day_noPU = LR_noPU.transform(test_data.select('features')).join(test_data, 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_noPU = (predict_4th_day_noPU.filter(predict_4th_day_noPU.prediction == predict_4th_day_noPU.label).count())\\\n",
    "/(predict_4th_day_noPU.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_noPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
